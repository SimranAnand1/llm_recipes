{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ece48bbf-ddc0-4507-a733-83c5b3c1c20d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_no_input(row):\n",
    "    return (\"Below is an instruction that describes a task. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Response:\\n\").format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b795343f-0356-4689-8bc6-9ac650716c8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_input(row):\n",
    "    return (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\").format_map(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4038166-085c-4b10-a56a-2bee0bd62436",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_prompt(row):\n",
    "    return prompt_no_input(row) if row[\"input\"] == \"\" else prompt_input(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c34cc42-c38c-4e6f-bfb6-0f32d48aef5d",
   "metadata": {},
   "source": [
    "## Why are we doing all this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0cbc7-7d45-45b4-8e32-f3153b0d9ce2",
   "metadata": {},
   "source": [
    "Let's load back the artifact we uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cb58a76e-c50c-4431-8584-3a4597c2a0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from wandb import Api\n",
    "\n",
    "api = Api()\n",
    "artifact = api.artifact('capecape/alpaca_ft/alpaca_gpt4_splitted:v4', type='dataset')\n",
    "dataset_dir = artifact.download()\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "    \n",
    "train_dataset = load_jsonl(f\"{dataset_dir}/alpaca_gpt4_train.jsonl\")\n",
    "eval_dataset = load_jsonl(f\"{dataset_dir}/alpaca_gpt4_eval.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31dd88-e90e-4697-b354-b39eed0fab3c",
   "metadata": {},
   "source": [
    "Because we need to tokenize this dataset in a very particular way, if we want the model to learn to predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e8683a4f-2ccc-45d1-88ef-17d3d3bc67fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Develop a script that prints out the Fibonacci sequence.',\n",
       " 'input': '',\n",
       " 'output': 'Here is a Python script that prints out the Fibonacci sequence:\\n\\n```\\n# number of elements in the sequence\\nn = int(input(\"Enter the number of elements in the sequence: \"))\\n\\n# initial two terms\\na = 0\\nb = 1\\n\\n# define a loop to generate the sequence\\nif n <= 0:\\n    print(\"Invalid input. The number of elements must be greater than 0.\")\\n\\nelif n == 1:\\n    print(a)\\n\\nelse:\\n    print(a, b, end=\" \")  # first two elements of the sequence\\n    for i in range(3, n+1):\\n        c = a + b\\n        print(c, end=\" \")\\n        a = b\\n        b = c\\n```\\n\\nTo use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cdea7bc4-1ec3-451e-ab00-549aa2056800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_dataset(dataset):\n",
    "    \"No EOS token yet\"\n",
    "    return [{\"prompt\":create_prompt(row), \n",
    "             \"output\":row[\"output\"], \n",
    "             \"example\":create_prompt(row) + row[\"output\"]} for row in dataset]\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "eval_dataset = format_dataset(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bf7f372-c939-4177-af8b-c5bd9b9ff36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDevelop a script that prints out the Fibonacci sequence.\\n\\n### Response:\\n',\n",
       " 'output': 'Here is a Python script that prints out the Fibonacci sequence:\\n\\n```\\n# number of elements in the sequence\\nn = int(input(\"Enter the number of elements in the sequence: \"))\\n\\n# initial two terms\\na = 0\\nb = 1\\n\\n# define a loop to generate the sequence\\nif n <= 0:\\n    print(\"Invalid input. The number of elements must be greater than 0.\")\\n\\nelif n == 1:\\n    print(a)\\n\\nelse:\\n    print(a, b, end=\" \")  # first two elements of the sequence\\n    for i in range(3, n+1):\\n        c = a + b\\n        print(c, end=\" \")\\n        a = b\\n        b = c\\n```\\n\\nTo use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.',\n",
       " 'example': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDevelop a script that prints out the Fibonacci sequence.\\n\\n### Response:\\nHere is a Python script that prints out the Fibonacci sequence:\\n\\n```\\n# number of elements in the sequence\\nn = int(input(\"Enter the number of elements in the sequence: \"))\\n\\n# initial two terms\\na = 0\\nb = 1\\n\\n# define a loop to generate the sequence\\nif n <= 0:\\n    print(\"Invalid input. The number of elements must be greater than 0.\")\\n\\nelif n == 1:\\n    print(a)\\n\\nelse:\\n    print(a, b, end=\" \")  # first two elements of the sequence\\n    for i in range(3, n+1):\\n        c = a + b\\n        print(c, end=\" \")\\n        a = b\\n        b = c\\n```\\n\\nTo use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "720c707b-3bce-4164-b8c1-3c3122200c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4162aec8-f2ba-45db-9633-817b416d4e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'meta-llama/Llama-2-7b-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58586813-7918-4578-9583-df14c5a6a6ad",
   "metadata": {},
   "source": [
    "### Packing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316d169-4292-41aa-a42d-cd49620a881c",
   "metadata": {},
   "source": [
    "We will pack multiple short examples into a longer chunk, so we can train more efficiently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a537da60-db69-42a7-8c66-0ea3756c2847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_sequence_len = 1024\n",
    "\n",
    "def pack(dataset, max_seq_len=max_sequence_len):\n",
    "    tkds_ids = tokenizer([s[\"example\"] for s in dataset])[\"input_ids\"]\n",
    "    \n",
    "    all_token_ids = []\n",
    "    for tokenized_input in tkds_ids:\n",
    "        all_token_ids.extend(tokenized_input + [tokenizer.eos_token_id])\n",
    "    \n",
    "    print(f\"Total number of tokens: {len(all_token_ids)}\")\n",
    "    packed_ds = []\n",
    "    for i in range(0, len(all_token_ids), max_seq_len+1):\n",
    "        input_ids = all_token_ids[i : i + max_seq_len+1]\n",
    "        if len(input_ids) == (max_seq_len+1):\n",
    "            packed_ds.append({\"input_ids\": input_ids[:-1], \"labels\": input_ids[1:]})  # this shift is not needed if using the model.loss\n",
    "    return packed_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6df54e-f6bc-4e56-aec2-014a19fc654c",
   "metadata": {},
   "source": [
    "The main idea here is that the instruction/output samples are short, so let's concatenate a bunch of them together separated by the `EOS` token. We can also pre-tokenize and pre-pack the dataset and make everything faster!  If we define a `max_seq_len = 1024` the code to pack would look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c78b4e9-2c7f-4aa1-b738-be04bc55b06b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 11486035\n",
      "Total number of tokens: 230341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11205"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_packed = pack(train_dataset)\n",
    "eval_ds_packed = pack(eval_dataset)\n",
    "len(train_ds_packed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df389230-911c-447c-a177-a18c22837020",
   "metadata": {},
   "source": [
    "Doing so, we end up with a little more than 11k sequences of lenght 1024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "7b103bd9-15ee-4505-97e6-c90ddaebc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = train_ds_packed[0]\n",
    "second = train_ds_packed[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11d033-58d8-4ded-9a56-e15e6f2f5069",
   "metadata": {},
   "source": [
    "## TRL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "344a798b-09ab-42c1-8914-340d31e7b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl.trainer.utils import ConstantLengthDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20305da1-26cc-47df-a35e-9ca561b5502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trl_train = ConstantLengthDataset(\n",
    "    tokenizer, \n",
    "    train_dataset,\n",
    "    dataset_text_field=\"example\",\n",
    "    seq_length=1024,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e650b610-3509-4cc9-891d-e9f712fc676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(trl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd4332b2-67b2-49b4-a8f1-b63c42d7345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_trl = next(it)\n",
    "second_trl = next(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62673a-b3a2-48bb-8263-922fa5f2b919",
   "metadata": {},
   "source": [
    "First example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2a1bac7-0230-4371-b94f-369c73f29f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trategies for virtual teams.\\n\\n### Response:\\n1. Regularly scheduled meetings: Scheduling regular meet'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(one[\"input_ids\"])[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55e72315-d21a-42e4-8a4e-07f33176f7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trategies for virtual teams.\\n\\n### Response:\\n1. Regularly scheduled meetings: Scheduling regular meet'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(one_trl[\"input_ids\"])[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412579b-9059-43fd-ae81-aa12d6e17d5b",
   "metadata": {},
   "source": [
    "Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9f03244b-e037-48dd-a40a-ac137bf51438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([29892, 2845, 491, 4863, 470, 7314, 21362, 29892, 6511, 3815], 1024)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second[\"input_ids\"][0:10], len(second[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed444e10-9ee9-4cf1-863c-4bc25e720606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', either by video or voice conference, allows team members to discuss ongoing projects, receive upda'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(second[\"input_ids\"])[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3791833-6d36-4bf5-979c-4471dfd6205e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  886, 29892,  2845,   491,  4863,   470,  7314, 21362, 29892,  6511]),\n",
       " 1024)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_trl[\"input_ids\"][0:10], len(second_trl[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "edf6db24-9791-4e67-b7a3-ca88f807200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ings, either by video or voice conference, allows team members to discuss ongoing projects, receive '"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(second_trl[\"input_ids\"])[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "704b12aa-8f6b-44cc-9a08-d459030da6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nks to the company's social media pages, a newsletter sign-up, and any important information such as\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(second[\"input_ids\"])[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1970b56f-2b33-4b0f-a34e-71e5bef06a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" links to the company's social media pages, a newsletter sign-up, and any important information such\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(second_trl[\"input_ids\"])[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d3753b-3464-4865-84fb-87d6605f66d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
