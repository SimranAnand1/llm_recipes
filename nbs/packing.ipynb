{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d325408-9bc2-47f7-a9d8-bf4dd1fb9bb7",
   "metadata": {},
   "source": [
    "# Exploring how to build a batch\n",
    "\n",
    "Different padding options here:\n",
    "- Standard Pack, where one just treats everything as a stream of text and cuts at max_seq_len. This can create split instruction.\n",
    "- Masked Pack, we pack as before, but we mask the instructions with -100, so the cross entropy don't backprop on those tokens.\n",
    "- Wayde had the idea of just padding so we don't have truncated instructions at the end/beginning of a batch. Just that, concatenate up to max_seq_len and then pad:\n",
    "\n",
    "> Let's see what `trl` has available to us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "01fd772c-28fa-48c7-9f4c-ddbb230e409b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prompt_no_input(row):\n",
    "    return (\"Below is an instruction that describes a task. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Response:\\n\").format_map(row)\n",
    "\n",
    "def prompt_input(row):\n",
    "    return (\"Below is an instruction that describes a task, paired with an input that provides further context. \"\n",
    "            \"Write a response that appropriately completes the request.\\n\\n\"\n",
    "            \"### Instruction:\\n{instruction}\\n\\n### Input:\\n{input}\\n\\n### Response:\\n\").format_map(row)\n",
    "\n",
    "def create_prompt(row):\n",
    "    return prompt_no_input(row) if row[\"input\"] == \"\" else prompt_input(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c34cc42-c38c-4e6f-bfb6-0f32d48aef5d",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee0cbc7-7d45-45b4-8e32-f3153b0d9ce2",
   "metadata": {},
   "source": [
    "Let's load back the artifact we uploaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb58a76e-c50c-4431-8584-3a4597c2a0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m:   2 of 2 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from wandb import Api\n",
    "\n",
    "api = Api()\n",
    "artifact = api.artifact('capecape/alpaca_ft/alpaca_gpt4_splitted:v4', type='dataset')\n",
    "dataset_dir = artifact.download()\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    data = []\n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "    \n",
    "train_dataset = load_jsonl(f\"{dataset_dir}/alpaca_gpt4_train.jsonl\")\n",
    "eval_dataset = load_jsonl(f\"{dataset_dir}/alpaca_gpt4_eval.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c31dd88-e90e-4697-b354-b39eed0fab3c",
   "metadata": {},
   "source": [
    "Because we need to tokenize this dataset in a very particular way, if we want the model to learn to predict the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e8683a4f-2ccc-45d1-88ef-17d3d3bc67fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instruction': 'Develop a script that prints out the Fibonacci sequence.',\n",
       " 'input': '',\n",
       " 'output': 'Here is a Python script that prints out the Fibonacci sequence:\\n\\n```\\n# number of elements in the sequence\\nn = int(input(\"Enter the number of elements in the sequence: \"))\\n\\n# initial two terms\\na = 0\\nb = 1\\n\\n# define a loop to generate the sequence\\nif n <= 0:\\n    print(\"Invalid input. The number of elements must be greater than 0.\")\\n\\nelif n == 1:\\n    print(a)\\n\\nelse:\\n    print(a, b, end=\" \")  # first two elements of the sequence\\n    for i in range(3, n+1):\\n        c = a + b\\n        print(c, end=\" \")\\n        a = b\\n        b = c\\n```\\n\\nTo use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cdea7bc4-1ec3-451e-ab00-549aa2056800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def format_dataset(dataset):\n",
    "    \"No EOS token yet\"\n",
    "    return [{\"prompt\":create_prompt(row), \n",
    "             \"output\":row[\"output\"], \n",
    "             \"example\":create_prompt(row) + row[\"output\"]} for row in dataset]\n",
    "train_dataset = format_dataset(train_dataset)\n",
    "eval_dataset = format_dataset(eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7bf7f372-c939-4177-af8b-c5bd9b9ff36a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'prompt': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDevelop a script that prints out the Fibonacci sequence.\\n\\n### Response:\\n',\n",
       " 'output': 'Here is a Python script that prints out the Fibonacci sequence:\\n\\n```\\n# number of elements in the sequence\\nn = int(input(\"Enter the number of elements in the sequence: \"))\\n\\n# initial two terms\\na = 0\\nb = 1\\n\\n# define a loop to generate the sequence\\nif n <= 0:\\n    print(\"Invalid input. The number of elements must be greater than 0.\")\\n\\nelif n == 1:\\n    print(a)\\n\\nelse:\\n    print(a, b, end=\" \")  # first two elements of the sequence\\n    for i in range(3, n+1):\\n        c = a + b\\n        print(c, end=\" \")\\n        a = b\\n        b = c\\n```\\n\\nTo use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.',\n",
       " 'example': 'Below is an instruction that describes a task. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nDevelop a script that prints out the Fibonacci sequence.\\n\\n### Response:\\nHere is a Python script that prints out the Fibonacci sequence:\\n\\n```\\n# number of elements in the sequence\\nn = int(input(\"Enter the number of elements in the sequence: \"))\\n\\n# initial two terms\\na = 0\\nb = 1\\n\\n# define a loop to generate the sequence\\nif n <= 0:\\n    print(\"Invalid input. The number of elements must be greater than 0.\")\\n\\nelif n == 1:\\n    print(a)\\n\\nelse:\\n    print(a, b, end=\" \")  # first two elements of the sequence\\n    for i in range(3, n+1):\\n        c = a + b\\n        print(c, end=\" \")\\n        a = b\\n        b = c\\n```\\n\\nTo use, enter the number of elements you want in the sequence when prompted. The script will print out the sequence up to the specified number of elements.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "720c707b-3bce-4164-b8c1-3c3122200c39",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aab1caba-73d9-4d53-9fb8-d584477b6224",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4162aec8-f2ba-45db-9633-817b416d4e57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'meta-llama/Llama-2-7b-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58586813-7918-4578-9583-df14c5a6a6ad",
   "metadata": {},
   "source": [
    "## Standard Packing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d316d169-4292-41aa-a42d-cd49620a881c",
   "metadata": {},
   "source": [
    "We will pack multiple short examples into a longer chunk, so we can train more efficiently!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a537da60-db69-42a7-8c66-0ea3756c2847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_seq_len = 1024\n",
    "\n",
    "def pack(dataset, max_seq_len=max_seq_len):\n",
    "    tkds_ids = tokenizer([s[\"example\"] for s in dataset])[\"input_ids\"]\n",
    "    \n",
    "    all_token_ids = []\n",
    "    for tokenized_input in tkds_ids:\n",
    "        all_token_ids.extend(tokenized_input + [tokenizer.eos_token_id])\n",
    "    \n",
    "    print(f\"Total number of tokens: {len(all_token_ids)}\")\n",
    "    packed_ds = []\n",
    "    for i in range(0, len(all_token_ids), max_seq_len):\n",
    "        input_ids = all_token_ids[i : i + max_seq_len]\n",
    "        if len(input_ids) == max_seq_len:\n",
    "            packed_ds.append({\"input_ids\": input_ids, \"labels\": input_ids})\n",
    "    return packed_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6df54e-f6bc-4e56-aec2-014a19fc654c",
   "metadata": {},
   "source": [
    "The main idea here is that the instruction/output samples are short, so let's concatenate a bunch of them together separated by the `EOS` token. We can also pre-tokenize and pre-pack the dataset and make everything faster!  If we define a `max_seq_len = 1024` the code to pack would look something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9c78b4e9-2c7f-4aa1-b738-be04bc55b06b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 11486035\n",
      "Total number of tokens: 230341\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11216"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds_packed = pack(train_dataset)\n",
    "eval_ds_packed = pack(eval_dataset)\n",
    "len(train_ds_packed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df389230-911c-447c-a177-a18c22837020",
   "metadata": {},
   "source": [
    "Doing so, we end up with a little more than 11k sequences of lenght 1024. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b103bd9-15ee-4505-97e6-c90ddaebc367",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = train_ds_packed[0]\n",
    "second = train_ds_packed[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c11d033-58d8-4ded-9a56-e15e6f2f5069",
   "metadata": {},
   "source": [
    "## TRL: Standard Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "344a798b-09ab-42c1-8914-340d31e7b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl.trainer.utils import ConstantLengthDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "20305da1-26cc-47df-a35e-9ca561b5502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trl_train = ConstantLengthDataset(\n",
    "    tokenizer, \n",
    "    train_dataset,\n",
    "    dataset_text_field=\"example\",\n",
    "    seq_length=max_seq_len,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e650b610-3509-4cc9-891d-e9f712fc676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(trl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fd4332b2-67b2-49b4-a8f1-b63c42d7345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_trl = next(it)\n",
    "second_trl = next(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd62673a-b3a2-48bb-8263-922fa5f2b919",
   "metadata": {},
   "source": [
    "First example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f2a1bac7-0230-4371-b94f-369c73f29f65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trategies for virtual teams.\\n\\n### Response:\\n1. Regularly scheduled meetings: Scheduling regular meet'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(one[\"input_ids\"])[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "55e72315-d21a-42e4-8a4e-07f33176f7a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'trategies for virtual teams.\\n\\n### Response:\\n1. Regularly scheduled meetings: Scheduling regular meet'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(one_trl[\"input_ids\"])[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6412579b-9059-43fd-ae81-aa12d6e17d5b",
   "metadata": {},
   "source": [
    "Second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "9f03244b-e037-48dd-a40a-ac137bf51438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([29892, 2845, 491, 4863, 470, 7314, 21362, 29892, 6511, 3815], 1024)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second[\"input_ids\"][0:10], len(second[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ed444e10-9ee9-4cf1-863c-4bc25e720606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "', either by video or voice conference, allows team members to discuss ongoing projects, receive upda'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(second[\"input_ids\"])[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c3791833-6d36-4bf5-979c-4471dfd6205e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  886, 29892,  2845,   491,  4863,   470,  7314, 21362, 29892,  6511]),\n",
       " 1024)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_trl[\"input_ids\"][0:10], len(second_trl[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "edf6db24-9791-4e67-b7a3-ca88f807200d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ings, either by video or voice conference, allows team members to discuss ongoing projects, receive '"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(second_trl[\"input_ids\"])[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "704b12aa-8f6b-44cc-9a08-d459030da6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"nks to the company's social media pages, a newsletter sign-up, and any important information such as\""
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(second[\"input_ids\"])[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5760b1-b0ce-4576-9605-c9467fecf741",
   "metadata": {},
   "source": [
    "they don't match as we don't use the built in cross entropy so we need to shift and drop a token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1970b56f-2b33-4b0f-a34e-71e5bef06a1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" links to the company's social media pages, a newsletter sign-up, and any important information such\""
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(second_trl[\"input_ids\"])[-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007c844b-4944-4172-84f5-26fd2c5465b8",
   "metadata": {},
   "source": [
    "## Wayde Packing: Truncate and Pad\n",
    "\n",
    "In this case, the instructions are not split at the en of a sequence, we pad to lenght accordingly.\n",
    "- We may end up with a bunch of useless EOS tokens at the end of sequences...\n",
    "- Attention masks may need to be updated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f6e7de9d-6ae6-4a5b-b7c0-3c26ed701660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_to_len(seq, max_seq_len, pad_token_id):\n",
    "    if len(seq) < max_seq_len:\n",
    "        seq = seq + [pad_token_id] * (max_seq_len - len(seq))\n",
    "    return seq\n",
    "\n",
    "def wpack(dataset, max_seq_len=max_seq_len):\n",
    "    max_seq_len = max_seq_len + 1  # to account for dropping one item\n",
    "    pad_token=tokenizer.pad_token_id\n",
    "    tkds_ids = tokenizer([s[\"example\"] for s in dataset])[\"input_ids\"]\n",
    "\n",
    "    packed_ds = [] \n",
    "    current_pack = []\n",
    "    for tokenized_input in tkds_ids:\n",
    "        if len(current_pack) < max_seq_len - len(tokenized_input):\n",
    "            current_pack.extend(tokenized_input + [tokenizer.eos_token_id])\n",
    "        else:\n",
    "            input_ids = pad_to_len(current_pack, max_seq_len, pad_token)\n",
    "            packed_ds.append({\"input_ids\": input_ids[:-1], \"labels\": input_ids[1:]})\n",
    "\n",
    "            #we start next pack\n",
    "            current_pack = tokenized_input + [tokenizer.eos_token_id]\n",
    "    return packed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "632abca9-83db-46bb-bdb8-3ab0c19890fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "wpack_train = wpack(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f6b72f39-6500-4f0b-afbe-394e2ab95eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "wone = wpack_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ec62dc50-3317-472b-a642-85dd8bbf3b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wone[\"labels\"][-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fdb8975e-b94d-494d-b8c5-8cc0a1094e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_tokens_total = 0\n",
    "total_tokens = 0\n",
    "for s in wpack_train:\n",
    "    pad_tokens_total += s[\"input_ids\"].count(2)\n",
    "    total_tokens += len(s[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f95c599-8e9b-4572-851f-0454d4167c18",
   "metadata": {},
   "source": [
    "15% of pad tokens, not bad 😭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5a0d9dbf-0968-45b1-8fe3-3fab8c9b4e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15874628915078348"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_tokens_total / total_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab74160-5652-4923-a646-b1de51f8cba9",
   "metadata": {},
   "source": [
    "## Masking of prompt\n",
    "We can leverage that cross-entropy has an `ingore_index` and label the inputs so they get ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "80b5f3e0-54f6-4caa-851d-74353764a36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_pack(dataset, max_seq_len=max_seq_len):\n",
    "    pad_token=tokenizer.pad_token_id\n",
    "    prompt_ids = tokenizer([s[\"prompt\"] for s in dataset])[\"input_ids\"]\n",
    "    outputs_ids = tokenizer([s[\"output\"] for s in dataset])[\"input_ids\"]\n",
    "\n",
    "    all_token_ids = []\n",
    "    all_labels_ids = []\n",
    "    for prompt, output in zip(prompt_ids, outputs_ids):\n",
    "        all_token_ids.extend(prompt + output + [tokenizer.eos_token_id])\n",
    "        all_labels_ids.extend([-100]*len(prompt) + output + [tokenizer.eos_token_id])\n",
    "\n",
    "    assert len(all_token_ids) == len(all_labels_ids), \"Error on tokenizing\"\n",
    "    \n",
    "    print(f\"Total number of tokens: {len(all_token_ids)}\")\n",
    "    packed_ds = []\n",
    "    for i in range(0, len(all_token_ids), max_seq_len):\n",
    "        input_ids = all_token_ids[i : i + max_seq_len]\n",
    "        label_ids = all_labels_ids[i : i + max_seq_len]\n",
    "        if len(input_ids) == max_seq_len:  # drop last\n",
    "            packed_ds.append({\"input_ids\": input_ids[:-1], \n",
    "                              \"labels\": label_ids[1:]})\n",
    "    return packed_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "64103859-1ce7-44ab-a915-5e8c9db35c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 11537060\n"
     ]
    }
   ],
   "source": [
    "mask_train = mask_pack(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "682aa610-f79a-47e8-a11f-8c926f52969c",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = mask_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "393475f1-547a-4467-9aba-fa5adbc9543b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' five communication strategies for virtual teams.\\n\\n### Response:\\n<s> 1. Regularly scheduled meetings'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(one[\"input_ids\"])[-100:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eaee99c2-d996-4a83-92ed-b0a6002456dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29892,\n",
       " 1244,\n",
       " 29915,\n",
       " 29879,\n",
       " 304,\n",
       " 7875,\n",
       " 29892,\n",
       " 2030,\n",
       " 322,\n",
       " 716,\n",
       " 394,\n",
       " 9345,\n",
       " 13,\n",
       " 1762,\n",
       " 15331,\n",
       " 29892,\n",
       " 5360,\n",
       " 29892,\n",
       " 29236,\n",
       " 29892,\n",
       " 297,\n",
       " 2462,\n",
       " 4366,\n",
       " 322,\n",
       " 4646,\n",
       " 13,\n",
       " 2831,\n",
       " 27994,\n",
       " 338,\n",
       " 19781,\n",
       " 263,\n",
       " 2578,\n",
       " 3745,\n",
       " 304,\n",
       " 4808,\n",
       " 13,\n",
       " 29909,\n",
       " 5828,\n",
       " 393,\n",
       " 2360,\n",
       " 4947,\n",
       " 2030,\n",
       " 29889,\n",
       " 2,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " -100,\n",
       " 1,\n",
       " 29871,\n",
       " 29896,\n",
       " 29889,\n",
       " 2169,\n",
       " 1070,\n",
       " 368,\n",
       " 21467,\n",
       " 5870,\n",
       " 886,\n",
       " 29901]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one[\"labels\"][-100:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f7e91a-8a5a-4b6e-bb06-4e172e1b0582",
   "metadata": {},
   "source": [
    "### Let's just check we are not messing things up...\n",
    "- BOS_TOKEN_ID: 1\n",
    "- EOS_TOKEN_ID: 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06148e-0fbe-446e-a248-c1f912bc0ee1",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26b76bc7-1626-47c9-982c-2a4623c48cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e9b08a6-cac6-4ec6-8c75-fd5a18f7aef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_id = 'meta-llama/Llama-2-7b-hf'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c819d67-a161-4702-94c3-fb53e5fa5a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = {\"prompt\": \"### Instruction: List three fruits\\n### Response:\\n\",\n",
    "          \"output\": \"- Apple\\n- Orange\\n- Strawberry\"}\n",
    "sample2 = {\"prompt\": \"### Instruction: Name two technology companies\\n### Response:\\n\",\n",
    "           \"output\": \"- Microsoft\\n- Oracle\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5ac05d1-54bb-4e2e-96a8-df6186aee4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = tokenizer(sample[\"prompt\"])[\"input_ids\"]\n",
    "example = tokenizer(sample[\"prompt\"] + sample[\"output\"])[\"input_ids\"] + [tokenizer.eos_token_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f54c74e-d8ec-410d-8e9d-5e1899aed477",
   "metadata": {},
   "outputs": [],
   "source": [
    "def printl(mylist):\n",
    "    return print(*mylist, sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebd8f41-c347-47d9-8a58-7f26305a3bb7",
   "metadata": {},
   "source": [
    "we get dual BOS tokens here! fuck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f013a5c1-1ad5-4c86-82d2-955caf4e4c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 835 2799 4080 29901 2391 2211 285 21211 13 2277 29937 13291 29901 13\n",
      "1 835 2799 4080 29901 2391 2211 285 21211 13 2277 29937 13291 29901 13 29899 12113 13 29899 26048 13 29899 624 1610 16344 2\n"
     ]
    }
   ],
   "source": [
    "printl(prompt)\n",
    "printl(example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2904bbb4-9db0-456d-a4d9-375111aa752e",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = copy.deepcopy(example)\n",
    "for i, _ in enumerate(prompt):\n",
    "    labels[i] = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4282357a-fb9b-43a2-8d34-cf732f7d1f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 29899 12113 13 29899 26048 13 29899 624 1610 16344 2\n"
     ]
    }
   ],
   "source": [
    "printl(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d99f6ed-e398-4b80-89eb-a50638cb4250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "example_mask = [1 if e>=0 else 0 for e in example]\n",
    "printl(example_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35cdc17c-72dd-4f60-ab62-c65d16321f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "labels_mask = [1 if e>=0 else 0 for e in labels]\n",
    "printl(labels_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "92f522b1-ee54-4a80-9bf6-5e28dfa50843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 29899 12113 13 29899 26048 13 29899 624 1610 16344 2\n"
     ]
    }
   ],
   "source": [
    "# example[~example_mask] = 0\n",
    "labels = [-100 if not lm else l for l, lm in zip(labels, labels_mask)]\n",
    "printl(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df3aa6b3-8eb7-4795-98ac-d8776cc3c49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 835 2799 4080 29901 2391 2211 285 21211 13 2277 29937 13291 29901 13 29899 12113 13 29899 26048 13 29899 624 1610 16344 2\n",
      "-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 29899 12113 13 29899 26048 13 29899 624 1610 16344 2\n",
      "1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "res = {\n",
    "    \"input_ids\": example,\n",
    "    \"labels\": labels,\n",
    "    \"attetion_mask\": example_mask,\n",
    "}\n",
    "printl(res[\"input_ids\"])\n",
    "printl(res[\"labels\"])\n",
    "printl(res[\"attetion_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1555755-fbc1-4439-b7d8-612f12bca919",
   "metadata": {},
   "source": [
    "### Check my implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9281b2f-a006-4c98-8d1f-3d79319e1f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llm_recipes.data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d191f8f2-3b69-45b9-abbd-cdd0eb9326f6",
   "metadata": {},
   "source": [
    "Standard Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a222352-d26d-4719-9d98-4537ba6da726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 73\n"
     ]
    }
   ],
   "source": [
    "ds = standard_packing([sample, sample2, sample], tokenizer, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d233b43-2551-42a2-b656-b97d9b9c247b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 835 2799 4080 29901 2391 2211 285 21211 13 2277 29937 13291 29901 13 29899 12113 13 29899 26048 13 29899 624 1610 16344 2 1 835 2799 4080 29901 4408 1023 15483\n"
     ]
    }
   ],
   "source": [
    "printl(ds[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55238abd-80fe-4799-9544-98ce90f5e77d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ### Instruction: List three fruits\\n### Response:\\n- Apple\\n- Orange\\n- Strawberry</s><s> ### Instruction: Name two technology'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ds[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "606380c6-2643-4a3c-9641-945e9b5528e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 2277 29937 13291 29901 13 29899 7783 13 29899 15401 2 1 835 2799 4080 29901 2391 2211 285 21211 13 2277 29937 13291 29901 13 29899 12113 13 29899 26048 13 29899\n"
     ]
    }
   ],
   "source": [
    "printl(ds[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38820c63-6080-47b6-9bd8-25604328b237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### Response:\\n- Microsoft\\n- Oracle</s><s> ### Instruction: List three fruits\\n### Response:\\n- Apple\\n- Orange\\n-'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ds[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044838bc-2af9-4d0c-8769-b8d1dcff8a07",
   "metadata": {},
   "source": [
    "Truncated Packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1bb4415b-e96d-46ef-abc2-b44b86bcaf9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pad_packing([sample, sample2, sample], tokenizer, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e22b48f-2bac-4be1-a5ba-f4921312b412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 835 2799 4080 29901 2391 2211 285 21211 13 2277 29937 13291 29901 13 29899 12113 13 29899 26048 13 29899 624 1610 16344 2 2 2 2 2 2 2 2 2\n"
     ]
    }
   ],
   "source": [
    "printl(ds[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98915095-f870-4f73-a175-f30bd370c17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ### Instruction: List three fruits\\n### Response:\\n- Apple\\n- Orange\\n- Strawberry</s></s></s></s></s></s></s></s></s>'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ds[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "43224b26-3903-45f7-b07c-6ab852bf867e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 835 2799 4080 29901 4408 1023 15483 14582 13 2277 29937 13291 29901 13 29899 7783 13 29899 15401 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"
     ]
    }
   ],
   "source": [
    "printl(ds[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b1590f1-24c2-4cc1-8262-d083231a1f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ### Instruction: Name two technology companies\\n### Response:\\n- Microsoft\\n- Oracle</s></s></s></s></s></s></s></s></s></s></s></s></s></s>'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ds[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6bf9ea-b07d-4b86-ada9-22c5d33845a9",
   "metadata": {},
   "source": [
    "Packing and Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e503db3e-5ccc-430a-a445-8e3d4afb6e74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tokens: 73\n"
     ]
    }
   ],
   "source": [
    "ds = masking_and_packing([sample, sample2, sample], tokenizer, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eaa85324-dd50-48c8-ad57-527684d577f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 448 12113 13 29899 26048 13 29899 624 1610 16344 2 -100 -100 -100 -100 -100 -100 -100 -100 -100\n"
     ]
    }
   ],
   "source": [
    "printl(ds[0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bdbe1959-0b05-4557-a86d-9b5310d9d4bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ### Instruction: List three fruits\\n### Response:\\n - Apple\\n- Orange\\n- Strawberry</s><s> ### Instruction: Name two technology'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ds[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "89134bbd-8b32-465f-8e6c-2cd4132bb0f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100 -100 -100 -100 -100 448 7783 13 29899 15401 2 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 448 12113 13 29899 26048 13 29899 624\n"
     ]
    }
   ],
   "source": [
    "printl(ds[1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fd15ccd9-d1c4-466f-8e08-76625d5cb027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n### Response:\\n - Microsoft\\n- Oracle</s><s> ### Instruction: List three fruits\\n### Response:\\n - Apple\\n- Orange\\n-'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ds[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c549ba7a-cefc-40f8-ba77-c397401f694d",
   "metadata": {},
   "source": [
    "Packing, Truncating and Masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d0232791-ea24-40d1-a190-7067a5fb6d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pad_mask_packing([sample, sample2, sample], tokenizer, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "880f4883-e71d-4fad-8c8e-5043b5b41681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 448 12113 13 29899 26048 13 29899 624 1610 16344 2 2 2 2 2 2 2 2 2 2\n"
     ]
    }
   ],
   "source": [
    "printl(ds[0][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66e28547-26fc-4d9c-a137-06fa4e0e4b47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ### Instruction: List three fruits\\n### Response:\\n - Apple\\n- Orange\\n- Strawberry</s></s></s></s></s></s></s></s></s>'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ds[0][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "04c025db-91f2-46a4-9dc3-191fa9ddaa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 -100 448 7783 13 29899 15401 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n"
     ]
    }
   ],
   "source": [
    "printl(ds[1][\"labels\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b6195f5-9841-4615-a4a7-f1ed162e54f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> ### Instruction: Name two technology companies\\n### Response:\\n - Microsoft\\n- Oracle</s></s></s></s></s></s></s></s></s></s></s></s></s></s>'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(ds[1][\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea00c9c-b44b-4944-b874-e85276d17380",
   "metadata": {},
   "source": [
    "## Simplest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f2e4772e-d0fb-487f-ad12-1d165d532348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_and_pad(tokenizer):\n",
    "    def _inner(examples):\n",
    "        examples = [x[\"prompt\"]+x[\"output\"]+tokenizer.eos_token for x in examples]\n",
    "        batch_size = len(examples)\n",
    "        input_ids = tokenizer(examples, return_tensors='pt', padding=\"longest\")['input_ids']\n",
    "        batch = {'input_ids': input_ids[:, :-1], 'labels': input_ids[:, 1:]}\n",
    "        return batch\n",
    "    return _inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "3d0d202f-2be3-4f28-9f20-afc7de490ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "collate_fn = collate_and_pad(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2fe35923-94e6-49f5-9b2d-17b7ffb4264c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   835,  2799,  4080, 29901,  2391,  2211,   285, 21211,    13,\n",
       "           2277, 29937, 13291, 29901,    13, 29899, 12113,    13, 29899, 26048,\n",
       "             13, 29899,   624,  1610, 16344],\n",
       "         [    1,   835,  2799,  4080, 29901,  4408,  1023, 15483, 14582,    13,\n",
       "           2277, 29937, 13291, 29901,    13, 29899,  7783,    13, 29899, 15401,\n",
       "              2,     2,     2,     2,     2]]),\n",
       " 'labels': tensor([[  835,  2799,  4080, 29901,  2391,  2211,   285, 21211,    13,  2277,\n",
       "          29937, 13291, 29901,    13, 29899, 12113,    13, 29899, 26048,    13,\n",
       "          29899,   624,  1610, 16344,     2],\n",
       "         [  835,  2799,  4080, 29901,  4408,  1023, 15483, 14582,    13,  2277,\n",
       "          29937, 13291, 29901,    13, 29899,  7783,    13, 29899, 15401,     2,\n",
       "              2,     2,     2,     2,     2]])}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collate_fn([sample, sample2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6c6a56a4-32bc-43d3-ab89-8c2c13d6671f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ef636ed9-32d6-406a-a674-d35b3837da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = literal_eval(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1d041033-52b7-423d-83b1-10d4cde47da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bool"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f96d2b-7569-425a-b091-1bfa28b54491",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
